{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d993061-d381-43e2-9493-4230367ac0a3",
   "metadata": {},
   "source": [
    "# AUDIO ANALYSIS PROJECT - ASR TRANSCRIPTION & INITIAL NLP PIPELINE\n",
    "**Author:** S.Akil | **Mentor:** Resma Rani Nimalpuri  \n",
    "\n",
    "## Overview\n",
    "This notebook implements the ASR (Automatic Speech Recognition) transcription using OpenAI's Whisper model, followed by an initial NLP pipeline for text cleaning, tokenization, stopword removal, and lemmatization.  \n",
    "\n",
    "**Pipeline Flow:**  \n",
    "1. Fetch and load audio from an online URL (integrates with Step 3: Preprocessing).  \n",
    "2. Transcribe audio to raw text.  \n",
    "3. Process text into clean, lemmatized tokens (ready for Step 5: Topic Segmentation).  \n",
    "\n",
    "**Sample Input:** A public-domain audiobook clip from LibriVox (Sherlock Holmes, Chapter 1).  \n",
    "**Expected Output:** `transcript.txt` (raw text) and `processed_tokens.txt` (NLP-ready tokens).  \n",
    "\n",
    "**Run Instructions:** Execute cells top-to-bottom. First-time NLTK/Whisper downloads may take 1-2 minutes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5509f006-62ec-4efa-9dc8-46c185f79dc6",
   "metadata": {},
   "source": [
    "# Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9236320-0f9c-414f-bed1-be4c4eceef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Explanation: Whisper for ASR, NLTK for NLP, requests/librosa for audio handling from URLs.\n",
    "# Run this cell first to verify installs‚Äîno outputs expected beyond potential NLTK downloads.\n",
    "\n",
    "import whisper  # pip install openai-whisper (for transcription)\n",
    "import nltk    # pip install nltk (for tokenization, stopwords, lemmatization)\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import requests  # For fetching audio from URLs\n",
    "import librosa   # For loading/resampling audio (pip install librosa)\n",
    "import io        # For in-memory byte handling\n",
    "import os        # For file paths/saving outputs\n",
    "\n",
    "# Download NLTK data (runs once; quiet mode for cleanliness)\n",
    "nltk.download('punkt', quiet=True)       # For tokenization\n",
    "nltk.download('stopwords', quiet=True)   # For stopwords\n",
    "nltk.download('wordnet', quiet=True)     # For lemmatization\n",
    "nltk.download('omw-1.4', quiet=True)     # For multilingual lemmatization support\n",
    "\n",
    "print(\"‚úÖ Libraries loaded successfully! NLTK data ready. Proceed to next cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f182d23-9ef3-4bcd-b463-bf81c68a89cf",
   "metadata": {},
   "source": [
    "# Step 2: Function to Fetch and Load Audio from Online URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0057ac-527c-42bf-bffd-14ebfec6170a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Explanation: Downloads audio from URL and loads as a NumPy array for Whisper.\n",
    "#              Assumes pre-cleaning from Step 3, but resamples to 16kHz mono.\n",
    "# Usage: Call this in execution cell; handles errors gracefully.\n",
    "\n",
    "def load_audio_from_url(audio_url):\n",
    "    \"\"\"\n",
    "    Fetches audio from URL and loads as a numpy array for Whisper.\n",
    "    Args: audio_url (str) - URL to MP3/WAV file.\n",
    "    Returns: audio (np.array) - Loaded audio data at 16kHz mono.\n",
    "    \"\"\"\n",
    "    # Download the audio file\n",
    "    response = requests.get(audio_url)\n",
    "    if response.status_code != 200:\n",
    "        raise ValueError(f\"‚ùå Failed to fetch audio from {audio_url} (Status: {response.status_code}). Check URL or network.\")\n",
    "    \n",
    "    # Load into librosa (handles MP3 to WAV conversion/resampling)\n",
    "    audio_data, sr = librosa.load(io.BytesIO(response.content), sr=16000, mono=True)\n",
    "    \n",
    "    print(f\"‚úÖ Audio loaded: Duration ~{len(audio_data)/sr:.1f} seconds, Sample Rate: {sr} Hz\")\n",
    "    return audio_data\n",
    "\n",
    "# Quick Test (Optional: Uncomment to test alone)\n",
    "# test_url = \"https://archive.org/download/adventures_sherlock_holmes_rg_librivox/adventuresholmes_01_doyle.mp3\"\n",
    "# audio_test = load_audio_from_url(test_url)\n",
    "# print(\"Test complete‚Äîno errors!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d8db9e-ae9e-4d12-8f08-ae1e7be42172",
   "metadata": {},
   "source": [
    "# Step 3: ASR Transcription Function Using Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510da929-1347-4fbb-8d9f-461489886e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Explanation: Loads a Whisper model and transcribes the audio array to text.\n",
    "#              Auto-detects English; outputs clean text (no timestamps here).\n",
    "# Usage: Pass audio_data; tweak model_name for trade-offs (base=fast, medium=accurate).\n",
    "\n",
    "def transcribe_audio(audio_data, model_name='base'):\n",
    "    \"\"\"\n",
    "    Transcribes audio using Whisper ASR.\n",
    "    Args: audio_data (np.array) - Preprocessed audio array.\n",
    "          model_name (str) - Whisper model size (base/small/medium/large).\n",
    "    Returns: transcript (str) - Raw transcribed text.\n",
    "    \"\"\"\n",
    "    # Load Whisper model (downloads ~142MB for 'base' on first run; cached after)\n",
    "    print(f\"üîÑ Loading Whisper model '{model_name}'... (First run may take 1-2 min.)\")\n",
    "    model = whisper.load_model(model_name)\n",
    "    \n",
    "    # Transcribe (fp16=False for CPU; add language='en' if needed)\n",
    "    result = model.transcribe(audio_data, fp16=False)\n",
    "    \n",
    "    transcript = result['text'].strip()\n",
    "    print(f\"‚úÖ Transcription complete! Model: {model_name}\")\n",
    "    print(f\"üìù Raw Transcript Preview (first 200 chars): {transcript[:200]}...\")\n",
    "    return transcript\n",
    "\n",
    "# Quick Test (Optional: Uncomment after Cell 3 test)\n",
    "# transcript_test = transcribe_audio(audio_test)\n",
    "# print(\"Test complete‚Äîtranscription ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b2e3a2-86c4-47d1-b428-74fad826b502",
   "metadata": {},
   "source": [
    "# Step 4: Initial NLP Pipeline Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec87fb3e-219e-4ce3-8405-4e5f6ced3740",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Explanation: Cleans transcript, then: Tokenize ‚Üí Remove Stopwords ‚Üí Lemmatize.\n",
    "#              Outputs list of base-form tokens (e.g., 'running' ‚Üí 'run').\n",
    "#              English-focused; extend for multilingual later.\n",
    "\n",
    "def process_text_nlp(transcript):\n",
    "    \"\"\"\n",
    "    Applies NLP pipeline: Clean ‚Üí Tokenize ‚Üí Remove Stopwords ‚Üí Lemmatize.\n",
    "    Args: transcript (str) - Raw text from ASR.\n",
    "    Returns: processed_tokens (list) - List of lemmatized tokens.\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))  # English stopwords; customize as needed\n",
    "    \n",
    "    # Sub-step 4.1: Text Cleaning (lowercase, normalize spaces, basic punctuation strip)\n",
    "    cleaned_text = ' '.join(transcript.lower().split())  # Simple but effective\n",
    "    print(f\"üßπ Cleaned Text Preview: {cleaned_text[:200]}...\")\n",
    "    \n",
    "    # Sub-step 4.2: Tokenization\n",
    "    tokens = word_tokenize(cleaned_text)\n",
    "    print(f\"üî§ Tokens (first 10): {tokens[:10]} | Total: {len(tokens)}\")\n",
    "    \n",
    "    # Sub-step 4.3: Stopword Removal (keep alphabetic tokens only)\n",
    "    filtered_tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n",
    "    print(f\"üóëÔ∏è After Stopwords Removal (first 10): {filtered_tokens[:10]} | Total: {len(filtered_tokens)}\")\n",
    "    \n",
    "    # Sub-step 4.4: Lemmatization\n",
    "    processed_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    print(f\"üì¶ Lemmatized Tokens (first 10): {processed_tokens[:10]} | Final Total: {len(processed_tokens)}\")\n",
    "    \n",
    "    return processed_tokens\n",
    "\n",
    "# Quick Test (Optional: Uncomment after Cell 4 test)\n",
    "# tokens_test = process_text_nlp(transcript_test)\n",
    "# print(\"Test complete‚ÄîNLP ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8c6b15-2884-4a51-b2c7-457611eec9f4",
   "metadata": {},
   "source": [
    "# Step 5: End-to-End Pipeline Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be5b531-3d6c-4b31-b865-473f5bc07e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Explanation: Runs the full chain: Load ‚Üí Transcribe ‚Üí NLP Process.\n",
    "#              Uses sample URL; swap for your own (e.g., from preprocessing outputs).\n",
    "#              Saves files for review/Step 5 integration.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample online audio URL (verified working: Sherlock Holmes Ch. 1, ~28 min)\n",
    "    sample_url = \"https://archive.org/download/adventures_sherlock_holmes_rg_librivox/adventuresholmes_01_doyle.mp3\"\n",
    "    \n",
    "    print(\"üöÄ === Starting Full ASR + NLP Pipeline ===\")\n",
    "    \n",
    "    # Load audio from URL\n",
    "    audio_data = load_audio_from_url(sample_url)\n",
    "    \n",
    "    # Transcribe\n",
    "    transcript = transcribe_audio(audio_data, model_name='base')\n",
    "    \n",
    "    # Process with NLP\n",
    "    processed_tokens = process_text_nlp(transcript)\n",
    "    \n",
    "    # Final Results\n",
    "    print(\"\\nüèÅ === Pipeline Complete! ===\")\n",
    "    print(f\"üìä Original Transcript: {len(transcript.split())} words\")\n",
    "    print(f\"üìä Processed Tokens: {len(processed_tokens)}\")\n",
    "    print(f\"üìù Sample Processed Output (first 20): {' '.join(processed_tokens[:20])}...\")\n",
    "    \n",
    "    # Save Outputs (for next steps, e.g., topic modeling)\n",
    "    with open('transcript.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(transcript)\n",
    "    print(\"üíæ Saved: transcript.txt (raw ASR text)\")\n",
    "    \n",
    "    with open('processed_tokens.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(' '.join(processed_tokens))\n",
    "    print(\"üíæ Saved: processed_tokens.txt (NLP tokens)\")\n",
    "\n",
    "print(\"üéâ All done! Check saved files and outputs above.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
